# 回归问题

## 1 回归指标

常用回归算法的评价指标是MSE，RMSE，MAE、R-Squared

### 1.1 MAE (Mean Absolute Error) - 平均绝对误差

预测值h(x<sub>i</sub>)与真实值y<sub>i</sub>之间的差的绝对值，再求和取平均。

可以更好地反映预测值误差的实际情况。

![](https://img-blog.csdnimg.cn/20201012214625554.png#pic_center)

代码实现：

	def mae(y_test, y_true):
	    return np.sum(np.absolute(y_test - y_true)) / len(y_test)

调用sklearn包：

	from sklearn.metrics import mean_absolute_error
	mean_absolute_error(y_test,y_predict)


### 1.2 MAPE (Mean Absolute Percentage Error) - 平均绝对百分比误差

预测值y<up>^</up><sub>i</sub>与真实值y<sub>i</sub>之间的百分比误差的平均值。

计算预测值与真实值之间的差，再除以真实值，得到的就是百分比误差。然后，取这个百分比误差的绝对值，得到的就是绝对百分比误差。最后，再求和取平均。 

反映了模型预测的误差相对于真实值的大小。

![](https://img-blog.csdnimg.cn/20210618100224692.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80NDQ0MTEzMQ==,size_16,color_FFFFFF,t_70)

代码实现：

	def mean_absolute_percentage_error(y_test, y_predict): 
	    y_test, y_predict = np.array(y_test), np.array(y_predict)
	    return np.mean(np.abs((y_test - y_predict) / y_test)) * 100

sklearn中没有封装这个函数


### 1.3 MSE（Mean Square Error）- 均方误差

真实值y<sub>i</sub>与预测值y<sup>^</sup><sub>i</sub>的差值的平方，再求和取平均。

平方的形式便于求导，所以常被用作**线性回归的损失函数**。

![](https://img-blog.csdnimg.cn/20201012214605452.png#pic_center)

代码实现：

	def rmse(y_test, y_true):
	    return sp.mean((y_test - y_true) ** 2)

调用sklearn包：

	from sklearn.metrics import mean_squared_error
	mean_squared_error(y_test,y_predict)


### 1.4 RMSE（Root Mean Square Error）- 均方根误差

观测值与真实值之间的差值求平方，再求和取平均后开方。

常用来作为机器学习模型预测结果衡量的**标准**。

![](https://img-blog.csdnimg.cn/20201012214054882.png#pic_center)

代码实现：

	from math import sqrt
	
	def rmse(y_test, y_true):
	    return sp.sqrt(sp.mean((y_test - y_true) ** 2))

调用sklearn包：

	from sklearn.metrics import mean_squared_error
	from math import sqrt
	
	sqrt(mean_squared_error(y_test,y_predict)）

### 1.5 R-squared

又叫可决系数(coefficient of determination)也叫拟合优度，反映的是自变量x对因变量y的变动的解释的程度。越接近于1，说明模型拟合得越好。

![](https://img-blog.csdnimg.cn/20201012214834168.png#pic_center)

将TSS理解为全部按平均值预测，RSS理解为按模型预测，这就相当于去比较你模型预测和全部按平均值预测的比例，这个比例越小，则模型越精确。

将输出平均值的回归器作为基准模型
一个回归模型的mse除以基准模型的mse，就可以计算

* 如果和基准模型一样差， R<sup>2</sup> = 0，说明我们的模型跟瞎猜差不多。
* 如果完全预测正确，R<sup>2</sup> = 1，一般认为超过0.8的模型拟合优度比较高。
* 如果比基准模型还要差，R<sup>2</sup> 是负数， 没救了考虑换模型吧。

当数据分布方差比较大时，预测不准时，R<sup>2</sup>依然比较大，此时改评价指标就不太好

代码实现：

	def r2(y_test, y_true):
	    return 1 - ((y_test - y_true) ** 2).sum() / ((y_true - np.mean(y_true)) ** 2).sum()

调用sklearn包：

	from sklearn.metrics import r2_score
	r2_score(y_test,y_predict)


## 2 小结

1）R<sup>2</sup>越大越好，其余指标越小越好

2）单个指标使用情况

* 如果看重真实值和预测值的**绝对误差**，则选用MAE，MAE对极端值比较敏感
* 如果看重真实值和预测值的**差的平方**,则选用MSE或RMSE
* 如果存在**不同样本的真实值有量级差**或者更加关注预测和真实值的**百分比差异**的情况,最好选用MAPE
* 如果模型希望的是找到能够**解释目标y变动的因变量**,则选用R Squared更合适

3）多个指标配合使用的情况

* MAE和RMSE一起使用,可以看出样本误差的离散程度

	比如RMSE远大于MAE时,可以得知不同样例的误差差别很大

* MAE和MAPE一起使用,再结合y<sup>-</sup>，可以估算模型对不同数量级样例的拟合程度。

	比如MAE远大于MAPE*y<sup>-</sup>则可能是模型对真实值小的样本预测更准。可以考虑为不同数量级的样本建立不同的模型








